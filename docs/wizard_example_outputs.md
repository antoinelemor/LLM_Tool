# Social Science Wizard - Example Outputs

This file contains example prompts generated by the Social Science Wizard for different research scenarios.

## Example 1: Political Discourse Analysis

### Research Context
- **Project**: Canadian Parliamentary Debate Analysis
- **Data**: Hansard transcript excerpts (1-2 sentences)
- **Goal**: Classify policy themes and party positions

### Wizard Configuration
- **Annotation Type**: Categorical
- **Categories**: theme, party, sentiment

### Generated Prompt

```
You are a text annotator specializing in social_sciences. Analyzing Canadian parliamentary debates to identify policy themes, party positions, and sentiment towards various socio-economic issues.

Analyze the following data: One-sentence excerpts from Hansard transcripts discussing federal policies. Texts are in English and French, typically 15-50 words.

You must structure the output in JSON format. Write exclusively in JSON without any explanatory text.

**Task:** Classify each text according to the categories defined below. The categories must be clear, and appropriate values must be used.

**Expected keys:**
- "theme": "environment" if the text relates to environmental policy, climate change, pollution control, or ecological sustainability, "health" if the text relates to healthcare system, medical coverage, or public health issues, "economy" if the text relates to economic policy, fiscal matters, or financial issues, "null" if the text does not explicitly relate to any of these themes.
- "party": "LPC" if the text mentions or refers to the Liberal Party of Canada, its MPs, or its positions, "CPC" if the text mentions or refers to the Conservative Party of Canada, its MPs, or its positions, "NDP" if the text mentions or refers to the New Democratic Party, its MPs, or its positions, "BQ" if the text mentions or refers to the Bloc Québécois, its MPs, or its positions, "null" if the text does not explicitly relate to any party.
- "sentiment": "positive" if the text has a favorable or supportive tone, "neutral" if the text is factual without clear positive or negative tone, "negative" if the text has a critical or opposing tone.

**Instructions**
- Strictly follow the structure of the keys defined above.
- Ensure that all keys are present in the JSON, using `null` when necessary.
- Do not include keys that are not defined in the expected keys above.
- Write exclusively the JSON without any additional comments or explanations.
- Indicate only one 'theme' value for each text.
- Indicate only one 'party' value for each text.
- Indicate only one 'sentiment' value for each text.

**Example of an annotation for the text:**

The Prime Minister announced new funding for renewable energy projects across Canada.

**Example of JSON:**

{
  "theme": "environment",
  "party": "LPC",
  "sentiment": "positive"
}

**Example of an annotation for the text:**

Conservative MPs criticized the healthcare wait times in their latest report.

**Example of JSON:**

{
  "theme": "health",
  "party": "CPC",
  "sentiment": "negative"
}

Follow this structure for each text analyzed. No other comments or additional details beyond the requested JSON structure and the specified categories should be added.

**Expected JSON Keys**
{
  "theme": "",
  "party": "",
  "sentiment": ""
}
```

---

## Example 2: Media Framing Analysis

### Research Context
- **Project**: Climate Change Media Framing Study
- **Data**: News article headlines
- **Goal**: Identify framing strategies and attributed sources

### Wizard Configuration
- **Annotation Type**: Entity Extraction
- **Categories**: frame_type, actors (with actor_type)

### Generated Prompt

```
You are a text annotator specializing in social_sciences. Analyzing media framing of climate change issues in Canadian news outlets to understand how environmental topics are presented and which actors are featured.

Analyze the following data: Headlines from major Canadian newspapers (Globe and Mail, Toronto Star, La Presse) from 2020-2024, focusing on climate and environmental policy coverage.

You must structure the output in JSON format. Write exclusively in JSON without any explanatory text.

**Task:** Extract and classify the specified entities from each text. Identify all relevant entities and their types according to the categories below.

**Expected keys:**
- "frame_type": "economic_impact" if the text frames climate issues in terms of economic costs, benefits, or financial implications, "scientific_evidence" if the text frames climate issues based on research, data, or scientific findings, "political_conflict" if the text frames climate issues as political debate or partisan disagreement, "human_interest" if the text frames climate issues through personal stories or individual impacts, "null" if the text does not explicitly use any of these frames.
- "actors" (can be multiple values): List of actors, organizations, or individuals mentioned in the text.
- "actor_type": "government" if actors are government officials, departments, or agencies, "scientist" if actors are researchers, scientists, or academic institutions, "activist" if actors are environmental activists, NGOs, or advocacy groups, "industry" if actors are corporations, business groups, or industry representatives, "null" if no specific actor type is identifiable.

**Instructions**
- Strictly follow the structure of the keys defined above.
- Ensure that all keys are present in the JSON, using `null` when necessary.
- Do not include keys that are not defined in the expected keys above.
- Write exclusively the JSON without any additional comments or explanations.
- Indicate only one 'frame_type' value for each text.
- Indicate multiple 'actors' values as an array if multiple values are present.
- Indicate only one 'actor_type' value for each text.

**Example of an annotation for the text:**

Scientists warn carbon tax increases necessary to meet 2030 emissions targets

**Example of JSON:**

{
  "frame_type": "scientific_evidence",
  "actors": ["scientists"],
  "actor_type": "scientist"
}

**Example of an annotation for the text:**

Oil industry groups criticize Ottawa's climate plan as job killer

**Example of JSON:**

{
  "frame_type": "economic_impact",
  "actors": ["oil industry groups", "Ottawa"],
  "actor_type": "industry"
}

Follow this structure for each text analyzed. No other comments or additional details beyond the requested JSON structure and the specified categories should be added.

**Expected JSON Keys**
{
  "frame_type": "",
  "actors": [""],
  "actor_type": ""
}
```

---

## Example 3: Social Media Content Moderation

### Research Context
- **Project**: Online Discourse Toxicity Detection
- **Data**: Social media comments
- **Goal**: Identify toxic content and categorize severity

### Wizard Configuration
- **Annotation Type**: Categorical
- **Categories**: toxicity_present, toxicity_type, severity_level

### Generated Prompt

```
You are a text annotator specializing in social_sciences. Analyzing social media comments to detect and classify toxic discourse patterns for content moderation research.

Analyze the following data: User comments from public political discussion forums and social media platforms, typically 10-100 words, containing political commentary.

You must structure the output in JSON format. Write exclusively in JSON without any explanatory text.

**Task:** Classify each text according to the categories defined below. The categories must be clear, and appropriate values must be used.

**Expected keys:**
- "toxicity_present": "yes" if the text contains any form of toxic, harmful, or offensive content, "no" if the text does not contain toxic content.
- "toxicity_type" (can be multiple values): "hate_speech" if the text contains hateful language targeting groups based on identity, "personal_attack" if the text contains direct insults or attacks on individuals, "profanity" if the text contains excessive or aggressive profanity, "threat" if the text contains threats or violent language, "null" if no toxicity is present.
- "severity_level": "low" if toxic content is mild or borderline, "moderate" if toxic content is clearly inappropriate but not extreme, "high" if toxic content is severe, dangerous, or violates platform policies, "null" if no toxicity is present.

**Instructions**
- Strictly follow the structure of the keys defined above.
- Ensure that all keys are present in the JSON, using `null` when necessary.
- Do not include keys that are not defined in the expected keys above.
- Write exclusively the JSON without any additional comments or explanations.
- Indicate only one 'toxicity_present' value for each text.
- Indicate multiple 'toxicity_type' values as an array if multiple values are present.
- Indicate only one 'severity_level' value for each text.

**Example of an annotation for the text:**

This policy is idiotic and whoever supports it should be ashamed

**Example of JSON:**

{
  "toxicity_present": "yes",
  "toxicity_type": ["personal_attack"],
  "severity_level": "low"
}

**Example of an annotation for the text:**

I disagree with this approach and think there are better alternatives

**Example of JSON:**

{
  "toxicity_present": "no",
  "toxicity_type": null,
  "severity_level": null
}

Follow this structure for each text analyzed. No other comments or additional details beyond the requested JSON structure and the specified categories should be added.

**Expected JSON Keys**
{
  "toxicity_present": "",
  "toxicity_type": [""],
  "severity_level": ""
}
```

---

## Example 4: Legislative Bill Analysis

### Research Context
- **Project**: Policy Innovation Tracking
- **Data**: Legislative bill summaries
- **Goal**: Classify innovation areas and implementation mechanisms

### Wizard Configuration
- **Annotation Type**: Categorical (with hierarchical structure)
- **Categories**: policy_area, innovation_type, mechanism, implementation_level

### Generated Prompt

```
You are a text annotator specializing in social_sciences. Tracking policy innovation in Canadian federal and provincial legislation to understand how new policy ideas emerge and spread across jurisdictions.

Analyze the following data: Bill summaries from federal Parliament and provincial legislatures, typically 50-200 words, describing proposed legislation.

You must structure the output in JSON format. Write exclusively in JSON without any explanatory text.

**Task:** Classify each text according to the categories defined below. The categories must be clear, and appropriate values must be used.

**Expected keys:**
- "policy_area" (can be multiple values): "social_policy" if the bill relates to social programs, welfare, or social services, "environmental_policy" if the bill relates to environmental protection, climate action, or natural resources, "economic_policy" if the bill relates to taxation, trade, industry, or economic development, "governance" if the bill relates to institutional reform, electoral systems, or government operations, "null" if the bill does not clearly fit these areas.
- "innovation_type": "new_approach" if the bill introduces a novel policy instrument or approach not previously used, "borrowed" if the bill adapts policy from another jurisdiction, "incremental" if the bill modifies or expands existing policy, "null" if innovation type is not identifiable.
- "mechanism": "regulation" if the bill primarily uses regulatory instruments, "incentive" if the bill primarily uses financial incentives or subsidies, "public_service" if the bill primarily creates or modifies public services, "information" if the bill primarily uses information campaigns or transparency measures, "null" if mechanism is not specified.
- "implementation_level": "federal" if the bill is federal legislation, "provincial" if the bill is provincial/territorial legislation, "municipal" if the bill relates to municipal powers, "shared" if the bill involves multiple levels of government.

**Instructions**
- Strictly follow the structure of the keys defined above.
- Ensure that all keys are present in the JSON, using `null` when necessary.
- Do not include keys that are not defined in the expected keys above.
- Write exclusively the JSON without any additional comments or explanations.
- Indicate multiple 'policy_area' values as an array if multiple values are present.
- Indicate only one 'innovation_type' value for each text.
- Indicate only one 'mechanism' value for each text.
- Indicate only one 'implementation_level' value for each text.

**Example of an annotation for the text:**

Bill C-123 establishes a federal carbon pricing framework requiring provinces to implement minimum carbon pricing or adopt the federal backstop system.

**Example of JSON:**

{
  "policy_area": ["environmental_policy", "economic_policy"],
  "innovation_type": "new_approach",
  "mechanism": "regulation",
  "implementation_level": "shared"
}

**Example of an annotation for the text:**

This bill increases the existing child benefit payment by $50 per month for families earning under $80,000.

**Example of JSON:**

{
  "policy_area": ["social_policy"],
  "innovation_type": "incremental",
  "mechanism": "incentive",
  "implementation_level": "federal"
}

Follow this structure for each text analyzed. No other comments or additional details beyond the requested JSON structure and the specified categories should be added.

**Expected JSON Keys**
{
  "policy_area": [""],
  "innovation_type": "",
  "mechanism": "",
  "implementation_level": ""
}
```

---

## Tips for Using These Examples

1. **Copy and Modify**: Use these prompts as templates for your own research
2. **Adjust Definitions**: Modify value definitions to match your specific context
3. **Add Examples**: Include your own examples for better LLM performance
4. **Test Iteratively**: Start with a small sample and refine the prompt
5. **Save Variants**: Keep different versions for different data types or time periods
