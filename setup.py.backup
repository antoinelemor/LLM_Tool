#!/usr/bin/env python3
"""
PROJECT:
-------
LLMTool

TITLE:
------
setup.py

MAIN OBJECTIVE:
---------------
This script provides the complete setup configuration for the LLMTool package,
including all dependencies, entry points, and metadata.

Dependencies:
-------------
- setuptools
- sys

MAIN FEATURES:
--------------
1) Complete package metadata
2) All dependencies from both annotation and training modules
3) Entry points for CLI execution
4) Optional dependencies for advanced features
5) Development dependencies

Author:
-------
Antoine Lemor
"""

from setuptools import setup, find_packages
from pathlib import Path

# Read README for long description
this_directory = Path(__file__).parent
long_description = (this_directory / "README.md").read_text(encoding="utf-8") if (this_directory / "README.md").exists() else ""

# Version
__version__ = "1.0.0"

# Core dependencies that are always needed
CORE_DEPENDENCIES = [
    # Data manipulation
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    "openpyxl>=3.1.0",  # Excel support
    "pyarrow>=18.0.0",  # Parquet support
    "pyreadr>=0.5.0",   # RData/RDS support

    # Database
    "sqlalchemy>=2.0.0",
    "psycopg2-binary>=2.9.0",

    # JSON and data validation
    "pydantic>=2.0.0",
    "jsonschema>=4.0.0",

    # CLI and interface
    "rich>=14.0.0",
    "tqdm>=4.65.0",
    "inquirer>=3.0.0",

    # Language detection (high accuracy)
    "lingua-language-detector>=2.0.0",

    # Logging
    "loguru>=0.7.0",

    # Utilities
    "python-dotenv>=1.0.0",
    "click>=8.0.0",
    "requests>=2.28.0",
    "pyyaml>=6.0.0",
    "python-dateutil>=2.8.0",
]

# LLM and AI dependencies
LLM_DEPENDENCIES = [
    # OpenAI API
    "openai>=1.0.0",

    # Local LLM support
    "ollama>=0.6.0",

    # Transformers and deep learning
    "transformers>=4.35.0",
    "torch>=2.0.0",
    "accelerate>=1.0.0",
    "sentencepiece>=0.2.0",
    "protobuf>=3.20.0",
    "safetensors>=0.6.0",
    "tokenizers>=0.20.0",
]

# Training dependencies
TRAINING_DEPENDENCIES = [
    # Datasets and evaluation
    "datasets>=4.0.0",
    "evaluate>=0.4.0",

    # Machine learning
    "scikit-learn>=1.5.0",
    "scipy>=1.14.0",

    # NLP utilities
    "nltk>=3.8.0",
    "sacremoses>=0.1.0",
]

# Optional advanced dependencies
ADVANCED_DEPENDENCIES = [
    # Additional LLM providers
    "anthropic>=0.18.0",
    "google-generativeai>=0.3.0",
    "llama-cpp-python>=0.2.0",

    # Annotation platforms
    "label-studio>=1.20.0",
    "label-studio-sdk>=2.0.0",

    # Alternative language detection
    "langdetect>=1.0.9",
    "fasttext>=0.9.2",
    "fasttext-wheel>=0.9.2",

    # Advanced ML features
    "sentence-transformers>=2.2.0",
    "imbalanced-learn>=0.11.0",

    # Visualization and analysis
    "seaborn>=0.12.0",
    "matplotlib>=3.6.0",

    # Hyperparameter optimization
    "optuna>=3.3.0",

    # MLOps and experiment tracking
    "mlflow>=2.8.0",
    "wandb>=0.15.0",
    "tensorboard>=2.13.0",

    # Web serving
    "fastapi>=0.103.0",
    "uvicorn>=0.23.0",
    "gradio>=3.45.0",

    # Database extensions
    "redis>=5.0.0",
    "pymongo>=4.5.0",

    # Distributed computing
    "ray>=2.6.0",
    "dask[complete]>=2023.8.0",
]

# Development dependencies
DEV_DEPENDENCIES = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.7.0",
    "flake8>=6.1.0",
    "mypy>=1.5.0",
    "isort>=5.12.0",
    "pre-commit>=3.3.0",
    "ipykernel>=6.25.0",
    "jupyter>=1.0.0",
    "notebook>=7.0.0",
]

# Combine all required dependencies
ALL_DEPENDENCIES = (
    CORE_DEPENDENCIES +
    LLM_DEPENDENCIES +
    TRAINING_DEPENDENCIES
)

setup(
    name="llm-tool",
    version=__version__,
    author="Antoine Lemor",
    description="State-of-the-Art LLM-Powered Annotation & BERT Training Pipeline for Multilingual Text Classification",
    long_description=long_description,
    long_description_content_type="text/markdown",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Science/Research",
        "Intended Audience :: Developers",
        "Operating System :: OS Independent",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "Programming Language :: Python :: 3.12",
        "Programming Language :: Python :: 3.13",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
        "Topic :: Software Development :: Libraries :: Python Modules",
        "Topic :: Text Processing :: Linguistic",
        "Topic :: Text Processing :: General",
        "Environment :: Console",
        "Natural Language :: English",
        "Natural Language :: French",
        "Natural Language :: Spanish",
        "Natural Language :: German",
        "Natural Language :: Chinese (Simplified)",
        "Natural Language :: Arabic",
        "Framework :: Jupyter",
    ],
    python_requires=">=3.9",
    install_requires=ALL_DEPENDENCIES,
    extras_require={
        "advanced": ADVANCED_DEPENDENCIES,
        "dev": DEV_DEPENDENCIES,
        "all": ADVANCED_DEPENDENCIES + DEV_DEPENDENCIES,
    },
    entry_points={
        "console_scripts": [
            "llm-tool=llm_tool.__main__:main",
            "llmtool=llm_tool.__main__:main",
        ],
    },
    include_package_data=True,
    package_data={
        "llm_tool": [
            "data/*.json",
            "data/*.jsonl",
            "prompts/*.txt",
            "prompts/*.json",
            "configs/*.yaml",
            "configs/*.json",
            "docs/*.md",
        ],
    },
    zip_safe=False,
    keywords=[
        # Core functionality
        "llm",
        "annotation",
        "machine-learning",
        "natural-language-processing",
        "transformers",
        "bert",
        "gpt",
        "training",
        "benchmarking",
        "multilingual",
        "ai",
        "deep-learning",
        "data-annotation",
        "model-training",
        # Specific models and technologies
        "deberta",
        "roberta",
        "electra",
        "albert",
        "xlm-roberta",
        "camembert",
        "longformer",
        # LLM providers
        "openai",
        "claude",
        "anthropic",
        "gemini",
        "ollama",
        "local-llm",
        # Use cases
        "text-classification",
        "sequence-classification",
        "multi-label-classification",
        "social-science",
        "research-tool",
        "annotation-tool",
        # Technical features
        "language-detection",
        "multilingual-nlp",
        "pytorch",
        "huggingface",
        "transformer-models",
        "pipeline",
        "cli-tool",
        "interactive-cli",
        "model-benchmarking",
        "prompt-engineering",
    ],
)